{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from itertools import cycle\n",
    "import csv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Proxies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProxies(inURL):\n",
    "    \n",
    "    page = requests.get(inURL)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    terms = soup.find_all('tr')\n",
    "    IPs = []\n",
    "\n",
    "    for x in range(len(terms)):  \n",
    "        \n",
    "        term = str(terms[x])        \n",
    "        \n",
    "        if '<tr><td>' in str(terms[x]):\n",
    "            pos1 = term.find('d>') + 2\n",
    "            pos2 = term.find('</td>')\n",
    "\n",
    "            pos3 = term.find('</td><td>') + 9\n",
    "            pos4 = term.find('</td><td>US<')\n",
    "            \n",
    "            IP = term[pos1:pos2]\n",
    "            port = term[pos3:pos4]\n",
    "            \n",
    "            if '.' in IP and len(port) < 6:\n",
    "                IPs.append(IP + \":\" + port)\n",
    "                #print(IP + \":\" + port)\n",
    "\n",
    "    return IPs \n",
    "\n",
    "\n",
    "#Cycle through the proxies and get one to use \n",
    "proxyURL = \"https://www.us-proxy.org/\"\n",
    "pxs = getProxies(proxyURL)\n",
    "proxyPool = cycle(pxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['50.4.60.98:80',\n",
       " '3.87.226.254:80',\n",
       " '198.199.86.11:8080',\n",
       " '138.68.60.8:8080',\n",
       " '209.97.150.167:8080',\n",
       " '191.96.42.80:8080',\n",
       " '102.129.249.120:8080',\n",
       " '3.92.176.124:80',\n",
       " '162.144.106.161:3838',\n",
       " '212.87.220.2:3128']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pxs[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load  Webpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "url = 'https://www.indeed.com/jobs?q=software+engineer+intern&l=New+York%2C+NY'\n",
    "\n",
    "#Get all of the code of the website \n",
    "page = requests.get(url, proxies = {\"http\": next(proxyPool)})\n",
    "soup = BeautifulSoup(page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all job postings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# All the job postings are inside the td tag with the id resultsCol \n",
    "jobs = soup.find(id='resultsCol')\n",
    "\n",
    "#Each individual job posting is represented by a div with the class jobsearch-SerpJobCard\n",
    "job_elems = jobs.find_all('div', class_='jobsearch-SerpJobCard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_elems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop through job postings and extract info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Software Engineer Intern Balyasny 4.0\n",
      "New York, NY\n",
      "Participate in all parts of software development lifecycle – you will take part of the design, implementation, and rollout of production systems.\n",
      "https://www.indeed.com/viewjob?jk=8ff009504101ef2f&fccid=3187d6d05b329ebf&vjs=3 \n",
      "\n",
      "\n",
      "Software Engineer Intern PayPal 3.9\n",
      "New York, NY 10018 (Clinton area)\n",
      "Code high-volume and scalable software.We have opportunities in a wide range of areas including development, design, search, platform, test, quality, big data,…\n",
      "https://www.indeed.com/viewjob?jk=e01674d33559a721&fccid=978d9fd9799d55a8&vjs=3 \n",
      "\n",
      "\n",
      "Software Engineer Intern (Paid) at a VC-Funded Startup (Fall... Formula -\n",
      "New York, NY 10010 (Flatiron District area)\n",
      "You will work side by side with our product and engineering teams on a diverse set of challenges.A strong fundamental understanding of Computer Science through…\n",
      "https://www.indeed.com/viewjob?cmp=Formula&t=Software-Engineer-Intern&jk=145fb24b09799861 \n",
      "\n",
      "\n",
      "2020 Software Engineer Intern Bloomberg 3.9\n",
      "-\n",
      "Engineering interns take ownership of their projects under the mentorship of full-time software engineers.In addition to your projects, you'll participate in…\n",
      "https://www.indeed.com/viewjob?cmp=Bloomberg&t=ead/clk?mo=r&ad=-6NYlbfkN0Ab67y_gTDH9tSaT0HLOcX4Q3W4UsL2WfVRyJV-qqww-V4IRDL3wY_Uj3G0Z9WcuCadEl1sqFYiGHxheFGi79fT1AeZHRsCDrroYiWd3Ts3rhRE3ulOU3XhF92YBmikJt_jf5ystgiIaRK0B8BLaVlwz-mzVb93ddxcgKEBOtz9yhi0YYcDdSYXedIrEYZ5xZNU_uJrshVMVw5JZnVvE7dbazajPUg7Ghnt2W5rFg6U8CC-ETfpUMTGK2WMOQ7YXD2-CPo_AhvQUalrgK9HS6JkLfRIkS7-DGLUAY-jT3rQAWtSDbL0XELeNcd2m71FubCK1cvcgOwi-b3yXHMhExBII8M65YqMWOdqfMbOAB47pZ6ip6zLtZjs76A3-ZwMCAkq17lqfzAi6FC0ouDyHXiI9PceG1blbnWc_GkGe7D0bNoVb03clKHcZDRxM2aSIxSfp6EVcTPCAb6PciDXkltustMbHipvOj124m5-Y3Z6ISn5ifIVpidmeoT7hBzsx1Hnz4DAKfQkg9Jbo35jMx5MnGu6MmIMIKXbnWLr24WCeOmiBI70511_pgwCe3gdBWEV_kbdhrYkZ1IP6lYe2LRweLdk_SAI0AcOTDxCnSv3rzymcIHDR1TLng0nJIuXBfqXcvjBLC3s80SnuAxTifpgR6F7JbOQvXSwRkQd8GQSPUQLOCgkqwwvSxjn8rmXMO_xWH41sDGIND8goaDz3LHS1ZZfNYnLAstMQxsLqKCc7v8Wnu6EI1VU69DLxRwV-v3UqjJpcqeBHEfWKB0ThHE6h-vSFr&jk= \n",
      "\n",
      "\n",
      "Software Engineering Intern - Summer 2021 Better Mortgage Corporation -\n",
      "New York, NY\n",
      "We encourage proposals for projects off the beaten path, experimentation with different frameworks and libraries, and doing as you see fit to solve problems.\n",
      "https://www.indeed.com/viewjob?jk=0bd99118f7bba9c4&fccid=38428bc0dc4a9166&vjs=3 \n",
      "\n",
      "\n",
      "Software Developer Intern IDA 3.5\n",
      "New York, NY\n",
      "Programming language can be of your choice but necessary to collaborate with any other interns to ensure app functions seamlessly.\n",
      "https://www.indeed.com/viewjob?cmp=IDA&t=Software-Developer-Intern&jk=1386b297104ede6f \n",
      "\n",
      "\n",
      "Software Development Intern Sumitomo Mitsui Banking Corporation 3.4\n",
      "New York, NY 11205 (Clinton Hill area)\n",
      "Interested in software development, database design.General software development support including: record business support requests, change control and…\n",
      "https://www.indeed.com/viewjob?jk=13952319c5385c07&fccid=e6ac082831bf0db9&vjs=3 \n",
      "\n",
      "\n",
      "Machine Learning Engineer Intern Weber Shandwick 3.9\n",
      "New York, NY 10022 (Sutton Place area)\n",
      "As a Machine Learning Engineer intern, you would be directly involved with the data science and engineering team, working to create machine learning models and…\n",
      "https://www.indeed.com/viewjob?jk=2a31101ee669e1c5&fccid=6576828d514f6f5c&vjs=3 \n",
      "\n",
      "\n",
      "Software Development Engineer Intern, Summer 2021 MasterCard 4.1\n",
      "New York, NY 10011 (Flatiron District area)\n",
      "Mastercard’s software engineering teams leverage Agile development principles, advanced development and design practices, and an obsession over security,…\n",
      "https://www.indeed.com/viewjob?jk=2d5a0bcae9cd08cd&fccid=10b5c722d846df43&vjs=3 \n",
      "\n",
      "\n",
      "Software Engineer Internship Eulerity -\n",
      "New York, NY\n",
      "Our progressive proprietary software solution supports the creation, execution, and analysis of paid marketing across all major digital channels including…\n",
      "https://www.indeed.com/viewjob?cmp=Eulerity&t=Software-Engineer-Internship&jk=2ac3c4efc797c3da \n",
      "\n",
      "\n",
      "Intern Cowen, Inc -\n",
      "New York, NY 10019 (Midtown area)\n",
      "Cowen Investment Management is looking for a Software Development Intern on a part-time basis.The role will work closely with the Director of Technology and…\n",
      "https://www.indeed.com/viewjob?jk=50153828b82a8b44&fccid=77fef78ac719a2e2&vjs=3 \n",
      "\n",
      "\n",
      "Software Engineering Internship, Summer 2021 Etsy 4.4\n",
      "Brooklyn, NY 11201\n",
      "You'll also be able to use Etsy's Continuous Deployment architecture to push code to production whenever you please (and you'll probably push on your first day…\n",
      "https://www.indeed.com/viewjob?jk=c2a1c9a393c5e04d&fccid=9ecb91618c39a24f&vjs=3 \n",
      "\n",
      "\n",
      "Software Engineer, Internship Palantir Technologies 4.3\n",
      "New York, NY 10014 (West Village area)\n",
      "Palantir's Product Development organization is made up of small teams of Software Engineers, each focusing on a specific aspect of a product.\n",
      "https://www.indeed.com/viewjob?jk=9a4b3d00ece703a7&fccid=c47ef3947291e221&vjs=3 \n",
      "\n",
      "\n",
      "Software Engineering Intern - Summer 2021 Cockroach Labs -\n",
      "New York, NY 10010 (Gramercy area)\n",
      "We are looking for extraordinary Backend, Full-stack, and Frontend Engineering Interns to join our team.You will bring your expertise to the table to provide…\n",
      "https://www.indeed.com/viewjob?jk=5102d773f6b8297c&fccid=65821e044148c3ad&vjs=3 \n",
      "\n",
      "\n",
      "Fullstack or Back-end or UX Engineering Intern Inspirave -\n",
      "-\n",
      "Exposure to software development as a CS graduate or equivalent, current studies, Bootcamp with Portfolio (deployed or on GitHub), or self-taught skills.\n",
      "https://www.indeed.com/viewjob?cmp=Inspirave&t=ead/clk?mo=r&ad=-6NYlbfkN0CQX70nsyY4fdsCOngI4EcKm6bzgiJvnPRADDTsAHBnDGFP7JOf-vyziHD6W5Xp-nQLTb8AvBvVgNUKDtPhL9_mmZcfmJBUB0NKrSJ-Al_JBnYJPvIls38g8JpFRdOZ46L7wHFLACNhRNy6CgORcbquMw6vpihq-mbDaYF4-ugvuvAlydBNlftoVR03K52RAXxltDagyzOUWKpdRSycAtmZLnLyE6tZbKArlIWMR-Ibgaz4RqqS-DAFdF6p5LgSra7Cb2DFlugrp4OMCHOlvDlav1LYfEWrlI1EqS0IFIsFokq-CkCjg-D1aBSSkhKfPhDOOG_s1rqJpC8GrVjdFzxuo3ed77p4UZkfo3g-LuMit0_C0HqkaJkfaTnkL8dQgHR_OXKu86hY5T9EfmhUEvp2pir7xPR3jIh5zsNeAWuTK45uwK7V0tnSabAejmz_ZUtuH&jk= \n",
      "\n",
      "\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "#Extract individual job info from job_elems, which is a list containing all the job listings on the page \n",
    "for desc in job_elems:\n",
    "    \n",
    "    #Extract only the job title \n",
    "    title = desc.find('h2', class_='title').text \n",
    "    \n",
    "    #Get rid of uncessary whitespace and the word 'new'\n",
    "    title = title.replace('new', '').replace('\\n', '') \n",
    "    \n",
    "    #Company name \n",
    "    company = desc.find('span', class_='company').text\n",
    "    company = company.replace('\\n', '')\n",
    "    \n",
    "    \n",
    "    #Not all companies have a rating \n",
    "    #If they don't have a rating, set rating to '-'\n",
    "    try:\n",
    "        rating = desc.find('span', class_='ratingsContent').text\n",
    "        rating = rating.replace('\\n', '')\n",
    "    except:\n",
    "        rating = '-'\n",
    "    \n",
    "    \n",
    "    #Not all job postings have a listed location\n",
    "    #If they don't have a rating, set rating to '-'\n",
    "    try:\n",
    "        location = desc.find('span', class_='location').text\n",
    "    except:\n",
    "        location = '-'\n",
    "    \n",
    "    \n",
    "    #Details of the job responsibilites \n",
    "    summary = desc.find('div', class_='summary').text\n",
    "    summary = summary.replace('\\n', '')\n",
    "    \n",
    "    \n",
    "    #Extract direct URL to the job listing \n",
    "    rawLink = desc.find('a', class_='jobtitle')\n",
    "    jobLink = rawLink.get('href')\n",
    "    jobLink = jobLink[jobLink.find('?') + 1 : ]\n",
    "    jobLink = ('https://www.indeed.com/viewjob?' + jobLink).replace('\\n', '')\n",
    "    \n",
    "    \n",
    "    #Some URLs are different \n",
    "    if 'jk=' not in jobLink:\n",
    "        rawLink = str(rawLink.get('href'))\n",
    "        jobLink = 'https://www.indeed.com/viewjob?cmp=' + company + '&t=' + rawLink[rawLink.find('jobs') + 5 : rawLink.rindex('-')] + '&jk=' + rawLink[rawLink.rindex('-') + 1 : rawLink.find('?')]\n",
    "\n",
    "        \n",
    "    print(title, company, rating)\n",
    "    print(location)\n",
    "    print(summary)\n",
    "    print(jobLink, '\\n' * 2)\n",
    "    \n",
    "print(len(job_elems))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractJobListings(url):\n",
    "    \n",
    "    page = requests.get(url, proxies = {\"http\": next(proxyPool)})\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "    jobs = soup.find(id='resultsCol')\n",
    "    job_elems = jobs.find_all('div', class_='jobsearch-SerpJobCard')\n",
    "    \n",
    "    #For Excel File \n",
    "    rows = []\n",
    "\n",
    "    for desc in job_elems:\n",
    "\n",
    "        #Extract only the job title \n",
    "        title = desc.find('h2', class_='title').text \n",
    "\n",
    "        #Get rid of uncessary whitespace and the word 'new'\n",
    "        title = title.replace('new', '').replace('\\n', '') \n",
    "\n",
    "        #Company name \n",
    "        company = desc.find('span', class_='company').text\n",
    "        company = company.replace('\\n', '')\n",
    "\n",
    "\n",
    "        #Not all companies have a rating \n",
    "        try:\n",
    "            rating = desc.find('span', class_='ratingsContent').text\n",
    "            rating = rating.replace('\\n', '')\n",
    "        except:\n",
    "            rating = '-'\n",
    "\n",
    "\n",
    "        #Not all job postings have a listed location\n",
    "        try:\n",
    "            location = desc.find('span', class_='location').text\n",
    "        except:\n",
    "            location = '-'\n",
    "\n",
    "\n",
    "        #Details of the job responsibilites \n",
    "        summary = desc.find('div', class_='summary').text\n",
    "        summary = summary.replace('\\n', '')\n",
    "\n",
    "\n",
    "        #Extract direct URL to the job listing \n",
    "        rawLink = desc.find('a', class_='jobtitle')\n",
    "        jobLink = rawLink.get('href')\n",
    "        jobLink = jobLink[jobLink.find('?') + 1 : ]\n",
    "        jobLink = ('https://www.indeed.com/viewjob?' + jobLink).replace('\\n', '')\n",
    "\n",
    "\n",
    "        #Some URLs are different \n",
    "        if 'jk=' not in jobLink:\n",
    "            rawLink = str(rawLink.get('href'))\n",
    "            jobLink = 'https://www.indeed.com/viewjob?cmp=' + company + '&t=' + rawLink[rawLink.find('jobs') + 5 : rawLink.rindex('-')] + '&jk=' + rawLink[rawLink.rindex('-') + 1 : rawLink.find('?')]\n",
    "            \n",
    "            \n",
    "        rows.append([title, company, rating, location, summary, jobLink])\n",
    "    \n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the total amount of pages to scrape through for all job listings found \n",
    "def getNumListings(url):\n",
    "    \n",
    "    page = requests.get(url, proxies = {\"http\": next(proxyPool)})\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "    rawNumJobs = soup.find(id='searchCountPages').text.replace('\\n', '')\n",
    "    numJobs = rawNumJobs[rawNumJobs.find('of') + 3 : rawNumJobs.find('jobs')]\n",
    "    \n",
    "    pages = (int(numJobs) // 15) + 1\n",
    "    return numJobs, pages    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Data for each row of the excel file will be stored in this \n",
    "csvRows = []\n",
    "\n",
    "def clean(stng):\n",
    "    \n",
    "    #We want to get rid of these characters \n",
    "    bad_chars = ['[', ']', '\"', ','] \n",
    "\n",
    "    for i in bad_chars : \n",
    "        stng = stng.replace(i, '') \n",
    "        \n",
    "    return stng\n",
    "\n",
    "def scrapeListings(position):\n",
    "    \n",
    "    position_ = position.replace(' ', '+')\n",
    "    page = 0\n",
    "    \n",
    "    totalJobs, pages = getNumListings('https://www.indeed.com/jobs?q=' + position_ + '&l=New+York%2C+NY')\n",
    "\n",
    "    print(totalJobs + 'jobs found!', str(pages) + ' pages')\n",
    "    \n",
    "    #Go through 10 pages of results \n",
    "    for x in range(pages):\n",
    "\n",
    "        url = 'https://www.indeed.com/jobs?q=' + position_ + '&l=New+York%2C+NY&start=' + str(page) \n",
    "        jobInfo = extractJobListings(url)\n",
    "\n",
    "        csvRows.append(jobInfo)\n",
    "\n",
    "        page += 10\n",
    "        \n",
    "        \n",
    "    # Column Names in the excel file  \n",
    "    fields = 'Title, Company, Rating, Location, Summary, Job Link\\n' \n",
    "\n",
    "    # Name of Excel file  \n",
    "    fileName = position + \" Job Postings.csv\"\n",
    "    \n",
    "    #Write to excel file \n",
    "    MyFile = open(fileName, 'w', encoding=\"utf-8\")\n",
    "\n",
    "    MyFile.write(fields)\n",
    "    \n",
    "    #Append the data to the rows of the file \n",
    "    for row in csvRows:\n",
    "        for job in row:\n",
    "            MyFile.write(clean(job[0]) + ',' + clean(job[1]) + ',' + clean(job[2]) + ',' + clean(job[3]) + ',' + clean(job[4]) + ',' + clean(job[5]))\n",
    "            MyFile.write('\\n')\n",
    "\n",
    "    MyFile.close()\n",
    "\n",
    "    print('\\nSaved as ' + fileName)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83 jobs found! 6 pages\n",
      "\n",
      "Saved as Software Engineer Intern Job Postings.csv\n"
     ]
    }
   ],
   "source": [
    "#Job Position you are searching for \n",
    "position = 'Software Engineer Intern'\n",
    "\n",
    "scrapeListings(position)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
